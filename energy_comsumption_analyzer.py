# å¯¼å…¥å¸¸ç”¨çš„ç§‘å­¦è®¡ç®—ä¸å¯è§†åŒ–åº“
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# å¯¼å…¥å¤„ç†æ—¶é—´åºåˆ—æ‰€éœ€çš„åº“
from datetime import datetime, timedelta
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler
from sklearn.ensemble import IsolationForest
from sklearn.svm import OneClassSVM
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split
# å¯¼å…¥æ—¶é—´åºåˆ—åˆ†æç›¸å…³æ¨¡å‹
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import adfuller
# å¯¼å…¥ PyTorch æ·±åº¦å­¦ä¹ ç›¸å…³ç»„ä»¶
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torch.nn.functional as F

import warnings
warnings.filterwarnings('ignore')
# è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿å®éªŒå¯å¤ç°
np.random.seed(3407)
torch.manual_seed(3407)
if torch.cuda.is_available():
    torch.cuda.manual_seed(3407)


class DFT_series_decomp(nn.Module):
    def __init__(self, top_k=5):
        super(DFT_series_decomp, self).__init__()
        self.top_k = top_k

    def forward(self, x):
        xf = torch.fft.rfft(x, dim=-1)
        freq = torch.abs(xf)
        freq[:, :, 0] = 0
        top_k_freq, top_list = torch.topk(freq, self.top_k, dim=-1)

        mask = torch.zeros_like(xf, dtype=torch.bool)
        mask.scatter_(-1, top_list, True)
        xf[~mask] = 0

        x_season = torch.fft.irfft(xf, n=x.size(-1))
        x_trend = x - x_season
        return x_season, x_trend


class MultiScaleSeasonMixing(nn.Module):
    def __init__(self, configs):
        super(MultiScaleSeasonMixing, self).__init__()
        self.down_sampling_layers = torch.nn.ModuleList(
            [
                nn.Sequential(
                    torch.nn.Linear(
                        configs.seq_len // (configs.down_sampling_window ** i),
                        configs.seq_len // (configs.down_sampling_window ** (i + 1)),
                    ),
                    nn.GELU(),
                    torch.nn.Linear(
                        configs.seq_len // (configs.down_sampling_window ** (i + 1)),
                        configs.seq_len // (configs.down_sampling_window ** (i + 1)),
                    ),
                )
                for i in range(configs.num_scales - 1)
            ]
        )

    def forward(self, season_list):
        batch_size, num_features, _ = season_list[0].shape
        # ã€ä¿®æ­£ã€‘: ä½¿ç”¨ .reshape() ä»£æ›¿ .view()
        season_list_flat = [s.reshape(batch_size * num_features, -1) for s in season_list]

        out_high = season_list_flat[0]
        out_season_list_flat = [out_high]

        for i in range(len(season_list_flat) - 1):
            out_low = season_list_flat[i + 1]
            out_low_res = self.down_sampling_layers[i](out_high)
            out_low = out_low + out_low_res
            out_high = out_low
            out_season_list_flat.append(out_high)

        # ã€ä¿®æ­£ã€‘: ä½¿ç”¨ .reshape() ä»£æ›¿ .view()
        out_season_list = [s.reshape(batch_size, num_features, -1) for s in out_season_list_flat]
        return out_season_list


class MultiScaleTrendMixing(nn.Module):
    def __init__(self, configs):
        super(MultiScaleTrendMixing, self).__init__()
        self.up_sampling_layers = torch.nn.ModuleList(
            [
                nn.Sequential(
                    torch.nn.Linear(
                        configs.seq_len // (configs.down_sampling_window ** (i + 1)),
                        configs.seq_len // (configs.down_sampling_window ** i),
                    ),
                    nn.GELU(),
                    torch.nn.Linear(
                        configs.seq_len // (configs.down_sampling_window ** i),
                        configs.seq_len // (configs.down_sampling_window ** i),
                    ),
                )
                for i in reversed(range(configs.num_scales - 1))
            ])

    def forward(self, trend_list):
        batch_size, num_features, _ = trend_list[0].shape
        # ã€ä¿®æ­£ã€‘: ä½¿ç”¨ .reshape() ä»£æ›¿ .view()
        trend_list_flat = [t.reshape(batch_size * num_features, -1) for t in trend_list]

        trend_list_reverse = trend_list_flat.copy()
        trend_list_reverse.reverse()

        out_low = trend_list_reverse[0]
        out_trend_list_flat = [out_low]

        for i in range(len(trend_list_reverse) - 1):
            out_high = trend_list_reverse[i + 1]
            out_high_res = self.up_sampling_layers[i](out_low)
            out_high = out_high + out_high_res
            out_low = out_high
            out_trend_list_flat.append(out_low)

        out_trend_list_flat.reverse()
        # ã€ä¿®æ­£ã€‘: ä½¿ç”¨ .reshape() ä»£æ›¿ .view()
        out_trend_list = [t.reshape(batch_size, num_features, -1) for t in out_trend_list_flat]
        return out_trend_list


class TimeMixer(nn.Module):
    """
    é›†æˆäº†å¤šå°ºåº¦åˆ†è§£ä¸æ··åˆçš„ Transformerã€‚
    """

    def __init__(self, input_size, output_size=90, d_model=64, nhead=8, num_layers=3, dropout=0.1,
                 num_scales=3, top_k=5, max_seq_len=1000):
        super(TimeMixer, self).__init__()
        self.input_size = input_size
        self.output_size = output_size
        self.d_model = d_model

        self.num_scales = num_scales
        self.top_k = top_k

        self.decomp_modules = None
        self.season_mixer = None
        self.trend_mixer = None

        self.input_projection = nn.Linear(input_size * 2, d_model)
        self.pos_encoding = nn.Parameter(torch.randn(1, max_seq_len, d_model))

        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)

        self.dropout = nn.Dropout(dropout)
        self.fc = nn.Linear(d_model, output_size)

    def _initialize_mixers(self, seq_len, device):
        """å†…éƒ¨å‡½æ•°ï¼Œç”¨äºåœ¨ç¬¬ä¸€æ¬¡å‰å‘ä¼ æ’­æ—¶åˆ›å»ºæ··åˆæ¨¡å—"""

        class Config:
            pass

        configs = Config()
        configs.seq_len = seq_len
        configs.num_scales = self.num_scales
        configs.down_sampling_window = 1

        self.decomp_modules = nn.ModuleList([DFT_series_decomp(top_k=self.top_k) for _ in range(self.num_scales)]).to(
            device)
        self.season_mixer = MultiScaleSeasonMixing(configs).to(device)
        self.trend_mixer = MultiScaleTrendMixing(configs).to(device)

    def forward(self, x):
        """
        å‰å‘ä¼ æ’­
        - x: è¾“å…¥æ—¶é—´åºåˆ—ï¼Œå½¢çŠ¶ä¸º [batch_size, seq_len, input_size]
        """
        batch_size, seq_len, _ = x.shape

        if self.season_mixer is None:
            self._initialize_mixers(seq_len, x.device)

        x_permuted = x.permute(0, 2, 1)  # -> [B, F, L]
        season_list, trend_list = [], []
        residual_trend = x_permuted
        for i in range(self.num_scales):
            season_part, trend_part = self.decomp_modules[i](residual_trend)
            season_list.append(season_part)
            trend_list.append(trend_part)
            residual_trend = trend_part

        mixed_season_list = self.season_mixer(season_list)
        mixed_trend_list = self.trend_mixer(trend_list)

        final_season_repr = sum(mixed_season_list).permute(0, 2, 1)
        final_trend_repr = sum(mixed_trend_list).permute(0, 2, 1)
        combined_repr = torch.cat([final_season_repr, final_trend_repr], dim=-1)

        x = self.input_projection(combined_repr)
        x = x + self.pos_encoding[:, :seq_len, :]
        x = self.transformer(x)

        x = x[:, -1, :]
        x = self.dropout(x)
        output = self.fc(x)

        return output



class LSTMForecaster(nn.Module):
    """ç”¨äºæ—¶é—´åºåˆ—é¢„æµ‹çš„ LSTM æ¨¡å‹"""

    def __init__(self, input_size, hidden_size=64, num_layers=2, output_size=90, dropout=0.2):
        """
        åˆå§‹åŒ– LSTM æ¨¡å‹ç»“æ„

        å‚æ•°:
        - input_size: æ¯ä¸ªæ—¶é—´æ­¥è¾“å…¥çš„ç‰¹å¾ç»´åº¦ï¼ˆä¾‹å¦‚å¤šä¸ªä¼ æ„Ÿå™¨çš„å€¼ï¼‰
        - hidden_size: LSTM æ¯å±‚éšè—çŠ¶æ€çš„ç»´åº¦
        - num_layers: LSTM å±‚æ•°ï¼ˆå¯å †å ï¼‰
        - dropout: Dropout æ¯”ä¾‹ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
        """
        super(LSTMForecaster, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers

        # æ„å»º LSTM æ¨¡å—ï¼Œè®¾ç½® batch_first=True ä»¥æ”¯æŒ [batch, time, feature] è¾“å…¥æ ¼å¼
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,
                            batch_first=True, dropout=dropout)

        # Dropout å±‚ç”¨äºæ­£åˆ™åŒ–
        self.dropout = nn.Dropout(dropout)

        # å…¨è¿æ¥å±‚å°†æœ€åæ—¶åˆ»çš„éšè—çŠ¶æ€æ˜ å°„ä¸ºå¤šä¸ªè¾“å‡ºå€¼çœ‹ï¼ŒçŸ­æœŸ90é•¿æœŸ365
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        """
        å‰å‘ä¼ æ’­è¿‡ç¨‹

        è¾“å…¥:
        - x: è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ä¸º [batch_size, sequence_length, input_size]

        è¿”å›:
        - output: é¢„æµ‹å€¼å¼ é‡ï¼Œå½¢çŠ¶ä¸º [batch_size, 1]
        """
        lstm_out, _ = self.lstm(x)  # LSTM è¾“å‡º shape: [batch, seq_len, hidden_size]
        last_output = lstm_out[:, -1, :]  # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºï¼ˆæœ€å…·ä»£è¡¨æ€§çš„çŠ¶æ€ï¼‰
        dropped = self.dropout(last_output)  # åŠ  Dropout
        output = self.fc(dropped)  # æ˜ å°„åˆ°è¾“å‡ºå€¼
        return output


class TransformerForecaster(nn.Module):
    """
    åŸºäº Transformer çš„æ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹ (å·²ä¿®æ”¹ä¸ºå¤šæ­¥é¢„æµ‹)
    """

    def __init__(self, input_size, output_size=90, d_model=64, nhead=8, num_layers=3, dropout=0.1):
        """
        åˆå§‹åŒ– Transformer é¢„æµ‹æ¨¡å‹

        å‚æ•°:
        - input_size: æ¯ä¸ªæ—¶é—´æ­¥çš„è¾“å…¥ç‰¹å¾ç»´åº¦
        - output_size: é¢„æµ‹æœªæ¥æ—¶é—´æ­¥çš„æ•°é‡ (ä¾‹å¦‚ï¼ŒçŸ­æœŸé¢„æµ‹90ä¸ªç‚¹)
        - d_model: Transformer ç¼–ç å™¨çš„å†…éƒ¨è¡¨ç¤ºç»´åº¦
        - nhead: å¤šå¤´æ³¨æ„åŠ›çš„å¤´æ•°
        - num_layers: ç¼–ç å™¨å±‚æ•°
        - dropout: Dropout æ¯”ä¾‹
        """
        super(TransformerForecaster, self).__init__()


        # è¾“å…¥æ˜ å°„ï¼šå°†è¾“å…¥ç‰¹å¾ç»´åº¦æŠ•å½±åˆ° d_model
        self.input_projection = nn.Linear(input_size, d_model)

        # ä½ç½®ç¼–ç ï¼ˆå¯å­¦ä¹ ï¼‰ï¼šæ·»åŠ æ—¶é—´ä½ç½®çš„å…ˆéªŒ
        # æ³¨æ„: å¯¹äºéå¸¸é•¿æˆ–é•¿åº¦ä¸å›ºå®šçš„åºåˆ—ï¼Œå›ºå®šçš„æ­£å¼¦/ä½™å¼¦ä½ç½®ç¼–ç å¯èƒ½æ›´ä¼˜
        self.pos_encoding = nn.Parameter(torch.randn(1000, d_model))

        # æ„å»º Transformer ç¼–ç å™¨å±‚
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)

        # Dropout å±‚
        self.dropout = nn.Dropout(dropout)

        # ã€æ”¹åŠ¨ 2ã€‘: ä¿®æ”¹è¾“å‡ºå±‚ï¼Œå°† d_model ç»´åº¦çš„è¡¨ç¤ºæ˜ å°„åˆ° output_size ä¸ªé¢„æµ‹å€¼
        self.fc = nn.Linear(d_model, output_size)


    def forward(self, x):
        """
        å‰å‘ä¼ æ’­

        è¾“å…¥:
        - x: è¾“å…¥æ—¶é—´åºåˆ—ï¼Œå½¢çŠ¶ä¸º [batch_size, seq_len, input_size]

        è¿”å›:
        - output: é¢„æµ‹å€¼ï¼Œå½¢çŠ¶ä¸º [batch_size, output_size]  <--- ã€æ”¹åŠ¨ 3ã€‘: è¿”å›å€¼çš„å½¢çŠ¶å·²æ”¹å˜
        """
        seq_len = x.size(1)

        # 1. è¾“å…¥æ˜ å°„åˆ° d_model ç©ºé—´
        x = self.input_projection(x)  # -> [batch_size, seq_len, d_model]

        # 2. æ·»åŠ ä½ç½®ç¼–ç 
        x = x + self.pos_encoding[:seq_len, :].unsqueeze(0)

        # 3. è¾“å…¥ Transformer ç¼–ç å™¨
        x = self.transformer(x)  # -> [batch_size, seq_len, d_model]

        # 4. å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºä½œä¸ºæ•´ä¸ªåºåˆ—çš„è¡¨ç¤º (ä¸ä½ çš„ LSTM æ¨¡å‹é€»è¾‘ä¸€è‡´)
        x = x[:, -1, :]  # -> [batch_size, d_model]
        x = self.dropout(x)

        # 5. é€šè¿‡å…¨è¿æ¥å±‚æ˜ å°„åˆ°æœ€ç»ˆçš„å¤šæ­¥é¢„æµ‹è¾“å‡º
        output = self.fc(x)  # -> [batch_size, output_size]

        return output


class TimeSeriesDataset(Dataset):
    """
    è‡ªå®šä¹‰ PyTorch æ•°æ®é›†ç±»ï¼Œç”¨äºå¤„ç†æ—¶é—´åºåˆ—æ•°æ®ã€‚
    æ­¤ç‰ˆæœ¬æ”¯æŒå¤šæ­¥é¢„æµ‹ (Multi-step Forecasting)ã€‚
    """

    def __init__(self, data, sequence_length, prediction_horizon=90, target_col='global_active_power'):
        """
        å‚æ•°:
        - data (pd.DataFrame): å·²æ’åºå’Œæ ‡å‡†åŒ–çš„æ—¶é—´åºåˆ—æ•°æ®ã€‚
        - sequence_length (int): è¾“å…¥åºåˆ—çš„é•¿åº¦ (æ»‘åŠ¨çª—å£å¤§å°)ã€‚
        - prediction_horizon (int): è¾“å‡ºåºåˆ—çš„é•¿åº¦ï¼Œå³éœ€è¦é¢„æµ‹çš„æœªæ¥æ—¶é—´æ­¥æ•°é‡ã€‚
                                   çŸ­æœŸ90ï¼Œé•¿æœŸ365ï¼Œå³å•æ­¥é¢„æµ‹ã€‚
        - target_col (str): éœ€è¦é¢„æµ‹çš„ç›®æ ‡åˆ—åç§°ã€‚
        """
        self.data = data
        self.sequence_length = sequence_length
        self.prediction_horizon = prediction_horizon
        self.target_col = target_col

    def __len__(self):
        """
        è®¡ç®—å¹¶è¿”å›æ•°æ®é›†ä¸­å¯ç”Ÿæˆçš„æ ·æœ¬æ€»æ•°ã€‚
        ç°åœ¨ï¼Œæ€»é•¿åº¦å¿…é¡»å‡å»è¾“å…¥åºåˆ—å’Œè¾“å‡ºåºåˆ—çš„é•¿åº¦ã€‚
        """
        # ä¸ºäº†ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„æ ·æœ¬ï¼Œæˆ‘ä»¬éœ€è¦ sequence_length çš„è¾“å…¥å’Œ prediction_horizon çš„è¾“å‡º
        # å› æ­¤æœ€åä¸€ä¸ªæ ·æœ¬çš„èµ·å§‹ç‚¹ (idx) å¿…é¡»ä¿è¯å…¶åæœ‰è¶³å¤Ÿçš„ (sequence_length + prediction_horizon) æ•°æ®ç‚¹
        return len(self.data) - self.sequence_length - self.prediction_horizon + 1

    def __getitem__(self, idx):
        """
        æ ¹æ®ç´¢å¼• `idx`ï¼Œæå–å¹¶è¿”å›ä¸€ä¸ª (è¾“å…¥åºåˆ—, ç›®æ ‡åºåˆ—) æ ·æœ¬å¯¹ã€‚

        è¿”å›:
        - x: ä» idx å¼€å§‹çš„é•¿åº¦ä¸º sequence_length çš„è¾“å…¥åºåˆ— (ç‰¹å¾)ã€‚
        - y: ç´§è·Ÿåœ¨è¾“å…¥åºåˆ—ä¹‹åçš„ã€é•¿åº¦ä¸º prediction_horizon çš„ç›®æ ‡åºåˆ—ã€‚
        """
        # æå–è¾“å…¥åºåˆ— x (ä¸ä¹‹å‰å®Œå…¨ç›¸åŒ)
        start_idx_x = idx
        end_idx_x = start_idx_x + self.sequence_length
        x = self.data.iloc[start_idx_x:end_idx_x].values

        # æå–è¾“å‡º/ç›®æ ‡åºåˆ— y
        start_idx_y = end_idx_x
        end_idx_y = start_idx_y + self.prediction_horizon

        # æˆ‘ä»¬åªä»ç›®æ ‡åˆ—ä¸­æå– y
        y = self.data[self.target_col].iloc[start_idx_y:end_idx_y].values

        # è½¬æ¢ä¸º PyTorch Tensors
        # x çš„å½¢çŠ¶æ˜¯ (sequence_length, num_features)
        # y çš„å½¢çŠ¶ç°åœ¨æ˜¯ (prediction_horizon,)
        return torch.FloatTensor(x), torch.FloatTensor(y)



class EnergyConsumptionAnalyzer:
    def __init__(self):
        """
        åˆå§‹åŒ–èƒ½è€—åˆ†æå™¨ç±»ï¼ˆå·²é€‚é…è®­ç»ƒ/æµ‹è¯•é›†åˆ†ç¦»ï¼‰ï¼š
        """
        # åŸå§‹æ•°æ®
        self.train_raw = None
        self.test_raw = None

        # å¤„ç†åçš„æ•°æ®ï¼ˆç‰¹å¾ + ç›®æ ‡ï¼‰
        self.train_processed = None
        self.test_processed = None

        # åˆ†ç¦»åçš„ç‰¹å¾ (X) å’Œç›®æ ‡ (y)
        self.X_train = None
        self.y_train = None
        self.X_test = None
        self.y_test = None

        # å­˜å‚¨æ¨¡å‹ã€é¢„æµ‹ç»“æœå’Œæ ‡å‡†åŒ–å™¨
        self.models = {}
        self.predictions = {}  # ä¸»è¦å­˜å‚¨å¯¹æµ‹è¯•é›†çš„é¢„æµ‹
        self.scalers = {}  # å­˜å‚¨ç”¨äºç‰¹å¾å’Œç›®æ ‡çš„æ ‡å‡†åŒ–å™¨

        # è®¾ç½®è®¡ç®—è®¾å¤‡
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ”§ Using device: {self.device}")



    def load_data(self, train_path: str, test_path: str):
        """
        åŠ è½½è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œå¹¶ä¸ºæ¯ä¸ªæ•°æ®é›†æ˜¾ç¤ºè¯¦ç»†çš„åŠ è½½ä¿¡æ¯ã€‚

        - åˆ†åˆ«ä» train_path å’Œ test_path åŠ è½½æ•°æ®ã€‚
        - å°†æ‰€æœ‰åˆ—åç»Ÿä¸€ä¸ºå°å†™æ ¼å¼ã€‚
        - ä¸ºæ¯ä¸ªæ•°æ®é›†æ‰“å°å½¢çŠ¶ã€åˆ—åã€æ€»æ¡æ•°å’Œå‰5è¡Œæ•°æ®é¢„è§ˆã€‚

        å‚æ•°:
            train_path (str): è®­ç»ƒé›† CSV æ–‡ä»¶çš„è·¯å¾„ã€‚
            test_path (str): æµ‹è¯•é›† CSV æ–‡ä»¶çš„è·¯å¾„ã€‚
        """
        # --- åŠ è½½è®­ç»ƒæ•°æ® ---
        print(f"ğŸ“¥ Loading training data from: {train_path}...")
        self.train_raw = pd.read_csv(train_path, sep=',')
        self.train_raw.columns = [col.lower() for col in self.train_raw.columns]

        print("\nâœ… Training data loaded successfully:")
        print(f"   - Shape: {self.train_raw.shape}")
        print(f"   - Columns: {list(self.train_raw.columns)}")
        print(f"   - æ•°æ®æ€»æ¡æ•°: {len(self.train_raw)}")
        print("   - å‰5è¡Œæ•°æ®é¢„è§ˆ:")
        # ä½¿ç”¨ to_string() ä¿è¯åœ¨åˆ—æ•°è¾ƒå¤šæ—¶ä¹Ÿèƒ½å®Œæ•´æ˜¾ç¤º
        print(self.train_raw.head().to_string())

        # ç”¨åˆ†éš”çº¿è®©è¾“å‡ºæ›´æ¸…æ™°
        print("\n" + "=" * 60 + "\n")

        # --- åŠ è½½æµ‹è¯•æ•°æ® ---
        print(f"ğŸ“¥ Loading testing data from: {test_path}...")
        self.test_raw = pd.read_csv(test_path, sep=',')
        self.test_raw.columns = [col.lower() for col in self.test_raw.columns]

        print("\nâœ… Testing data loaded successfully:")
        print(f"   - Shape: {self.test_raw.shape}")
        print(f"   - Columns: {list(self.test_raw.columns)}")
        print(f"   - æ•°æ®æ€»æ¡æ•°: {len(self.test_raw)}")
        print("   - å‰5è¡Œæ•°æ®é¢„è§ˆ:")
        print(self.test_raw.head().to_string())



    def _create_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        [ç§æœ‰æ–¹æ³•] ä¸ºç»™å®šçš„æ•°æ®é›†åˆ›å»ºæ‰€æœ‰æ—¶é—´ã€å‘¨æœŸã€æ»åå’Œæ»šåŠ¨ç‰¹å¾ã€‚
        """
        # åˆ›å»ºä¸€ä¸ªå‰¯æœ¬ä»¥é¿å…å¯¹åŸå§‹æ•°æ®è¿›è¡Œä¿®æ”¹
        data = df.copy()

        # --- æ—¶é—´ç´¢å¼•åˆ›å»º ---
        if not isinstance(data.index, pd.DatetimeIndex):
            if 'date' in data.columns:
                data['date'] = pd.to_datetime(data['date'], errors='coerce')
                if data['date'].isnull().any():
                    raise ValueError("âŒ 'date' column contains values that could not be parsed.")
                data.set_index('date', inplace=True)
            else:
                raise KeyError("âŒ Missing 'date' column to create datetime index.")

        # --- æ‰€æœ‰ç‰¹å¾å·¥ç¨‹é€»è¾‘ (ä¸æ‚¨æä¾›çš„ä»£ç ç›¸åŒ) ---
        data['year'] = data.index.year
        data['month'] = data.index.month
        data['day_of_week'] = data.index.dayofweek
        data['day_of_year'] = data.index.dayofyear
        data['quarter'] = data.index.quarter
        data['is_weekend'] = (data.index.dayofweek >= 5).astype(int)

        data['day_of_week_sin'] = np.sin(2 * np.pi * data['day_of_week'] / 7)
        data['day_of_week_cos'] = np.cos(2 * np.pi * data['day_of_week'] / 7)
        data['month_sin'] = np.sin(2 * np.pi * data['month'] / 12)
        data['month_cos'] = np.cos(2 * np.pi * data['month'] / 12)
        data['day_of_year_sin'] = np.sin(2 * np.pi * data['day_of_year'] / 365.25)
        data['day_of_year_cos'] = np.cos(2 * np.pi * data['day_of_year'] / 365.25)

        if all(col in data.columns for col in ['sub_metering_1', 'sub_metering_2', 'sub_metering_3']):
            data['total_sub_metering'] = (
                    data['sub_metering_1'] + data['sub_metering_2'] + data['sub_metering_3']
            )

        target_col = 'global_active_power'
        if target_col in data.columns:
            lags_in_days = [1, 2, 3, 7, 14, 30]
            for lag in lags_in_days:
                data[f'{target_col}_lag_{lag}_day'] = data[target_col].shift(lag)

            windows_in_days = [3, 7, 14, 30]
            for window in windows_in_days:
                data[f'{target_col}_rolling_mean_{window}_day'] = data[target_col].rolling(window).mean()
                data[f'{target_col}_rolling_std_{window}_day'] = data[target_col].rolling(window).std()

        return data



    def preprocess_data(self, target_col: str = 'global_active_power'):
        """
        å¯¹è®­ç»ƒé›†å’Œæµ‹è¯•é›†è¿›è¡Œå®Œæ•´çš„é¢„å¤„ç†æµç¨‹ï¼š
        1. å¯¹ä¸¤ä¸ªæ•°æ®é›†åº”ç”¨ç‰¹å¾å·¥ç¨‹ã€‚
        2. æ¸…ç†å› ç‰¹å¾å·¥ç¨‹äº§ç”Ÿçš„NaNå€¼ã€‚
        3. åˆ†ç¦»ç‰¹å¾(X)å’Œç›®æ ‡(y)ã€‚
        4. åŸºäºè®­ç»ƒé›†è¿›è¡Œæ•°æ®æ ‡å‡†åŒ–ï¼Œå¹¶åº”ç”¨åˆ°æµ‹è¯•é›†ï¼Œä»¥é˜²æ­¢æ•°æ®æ³„éœ²ã€‚
        """
        print("\nğŸ”§ Preprocessing data for both training and testing sets...")

        # --- 1. ç‰¹å¾å·¥ç¨‹ ---
        # å¯¹è®­ç»ƒé›†å’Œæµ‹è¯•é›†åˆ†åˆ«è°ƒç”¨ç‰¹å¾åˆ›å»ºå‡½æ•°
        self.train_processed = self._create_features(self.train_raw)
        self.test_processed = self._create_features(self.test_raw)
        print("   - Feature engineering applied to both sets.")

        # --- 2. æ¸…ç† NaN ---
        # åˆ é™¤å› æ»å/æ»šåŠ¨ç‰¹å¾äº§ç”Ÿçš„NaNè¡Œ
        self.train_processed.dropna(inplace=True)
        self.test_processed.dropna(inplace=True)
        print(
            f"   - NaN values dropped.  train shape: {self.train_processed.shape}, Test shape: {self.test_processed.shape}")

        # --- 3. åˆ†ç¦»ç‰¹å¾ (X) å’Œç›®æ ‡ (y) ---
        self.y_train = self.train_processed[[target_col]]
        self.X_train = self.train_processed.drop(columns=[target_col])
        self.y_test = self.test_processed[[target_col]]
        self.X_test = self.test_processed.drop(columns=[target_col])
        print("   - Features (X) and target (y) have been separated.")

        # --- 4. æ•°æ®æ ‡å‡†åŒ– (é˜²æ­¢æ•°æ®æ³„éœ²çš„å…³é”®æ­¥éª¤) ---
        # åˆ›å»ºç‰¹å¾æ ‡å‡†åŒ–å™¨
        feature_scaler = MinMaxScaler()
        # **åªç”¨è®­ç»ƒé›†ç‰¹å¾æ¥å­¦ä¹ **ç¼©æ”¾å‚æ•°ï¼Œç„¶ååº”ç”¨åˆ°è®­ç»ƒé›†
        self.X_train = pd.DataFrame(feature_scaler.fit_transform(self.X_train), columns=self.X_train.columns,
                                    index=self.X_train.index)
        # **ç”¨åŒä¸€ä¸ªï¼ˆå·²ç»å­¦ä¹ å¥½çš„ï¼‰æ ‡å‡†åŒ–å™¨**æ¥è½¬æ¢æµ‹è¯•é›†ç‰¹å¾
        self.X_test = pd.DataFrame(feature_scaler.transform(self.X_test), columns=self.X_test.columns,
                                   index=self.X_test.index)
        self.scalers['features'] = feature_scaler  # ä¿å­˜ï¼Œç”¨äºæœªæ¥é€†å‘è½¬æ¢

        # å¯¹ç›®æ ‡å˜é‡ä¹Ÿè¿›è¡Œæ ‡å‡†åŒ–
        target_scaler = MinMaxScaler()
        self.y_train = pd.DataFrame(target_scaler.fit_transform(self.y_train), columns=self.y_train.columns,
                                    index=self.y_train.index)
        self.y_test = pd.DataFrame(target_scaler.transform(self.y_test), columns=self.y_test.columns,
                                   index=self.y_test.index)
        self.scalers['target'] = target_scaler  # ä¿å­˜ï¼Œç”¨äºé€†å‘è½¬æ¢é¢„æµ‹ç»“æœ

        print("   - Data scaling complete (fit on train, transform on both).")
        print("âœ… Preprocessing finished. Data is ready for model training.")



    def prepare_sequences(self, data, sequence_length=90, target_col='global_active_power'):
        """
        ä¸ºæ—¶é—´åºåˆ—å»ºæ¨¡å‡†å¤‡æ•°æ®ï¼š
        - å°†è¾“å…¥ç‰¹å¾ä¸ç›®æ ‡åˆ—åˆ†å¼€è¿›è¡Œæ ‡å‡†åŒ–ï¼ˆStandardScalerï¼‰
        - è¿”å›æ ‡å‡†åŒ–åçš„æ•°æ® DataFrame åŠç‰¹å¾åˆ—ååˆ—è¡¨
        - ä¸ç›´æ¥åˆ‡åˆ†åºåˆ—ï¼Œè€Œæ˜¯ä½œä¸ºåºåˆ—æ„é€ å‰çš„é¢„å¤„ç†æ­¥éª¤

        å‚æ•°ï¼š
            data (pd.DataFrame): å·²ç»é¢„å¤„ç†è¿‡çš„ç‰¹å¾æ•°æ®
            sequence_length (int): æ¯ä¸ªæ ·æœ¬åŒ…å«çš„æ—¶é—´æ­¥æ•°é‡ï¼ˆç”¨å†å²90å¤©æ•°æ®åšé¢„æµ‹ï¼‰
            target_col (str): ç›®æ ‡å˜é‡åˆ—åï¼ˆé»˜è®¤ä¸º 'global_active_power'ï¼‰

        è¿”å›ï¼š
            scaled_data (pd.DataFrame): æ ‡å‡†åŒ–åçš„å®Œæ•´æ•°æ®ï¼ˆåŒ…å«ç‰¹å¾ + ç›®æ ‡ï¼‰
            feature_cols (list): æ‰€æœ‰ç‰¹å¾åˆ—åï¼ˆä¸å«ç›®æ ‡åˆ—ï¼‰
        """

        # ğŸ§© Step 1: æå–ç‰¹å¾åˆ—ï¼ˆæ’é™¤ç›®æ ‡åˆ—ï¼‰
        feature_cols = [col for col in data.columns if col != target_col]

        # ğŸ§ª Step 2: åˆå§‹åŒ–ä¸¤ä¸ªæ ‡å‡†åŒ–å™¨
        # - ä¸€ä¸ªç”¨äºç‰¹å¾
        # - ä¸€ä¸ªç”¨äºç›®æ ‡å˜é‡
        feature_scaler = StandardScaler()
        target_scaler = StandardScaler()

        # ğŸ§¼ Step 3: å¯¹ç‰¹å¾åˆ—å’Œç›®æ ‡åˆ—åˆ†åˆ«è¿›è¡Œæ ‡å‡†åŒ–
        scaled_features = feature_scaler.fit_transform(data[feature_cols])
        scaled_target = target_scaler.fit_transform(data[[target_col]])

        # ğŸ§± Step 4: å°†æ ‡å‡†åŒ–åçš„ç‰¹å¾å’Œç›®æ ‡åˆ—ç»„åˆæˆä¸€ä¸ª DataFrame
        scaled_data = pd.DataFrame(
            np.hstack([scaled_features, scaled_target]),  # æ°´å¹³å †å 
            columns=feature_cols + [target_col],  # ä¿æŒåˆ—åä¸€è‡´
            index=data.index  # ä¿ç•™æ—¶é—´ç´¢å¼•
        )

        # ğŸ’¾ Step 5: ä¿å­˜æ ‡å‡†åŒ–å™¨ï¼Œç”¨äºåç»­æ¨¡å‹é¢„æµ‹æ—¶åæ ‡å‡†åŒ–ï¼ˆinverse_transformï¼‰
        self.scalers['feature_scaler'] = feature_scaler
        self.scalers['target_scaler'] = target_scaler

        # âœ… è¿”å›æ ‡å‡†åŒ–åçš„æ•°æ®å’Œç‰¹å¾åˆ—ååˆ—è¡¨
        return scaled_data, feature_cols



    def train_pytorch_model(self, model_type='lstm', sequence_length=90, prediction_horizon=90, epochs=50, batch_size=32):
        """
        ä½¿ç”¨ PyTorch è®­ç»ƒç”¨äºæ—¶é—´åºåˆ—é¢„æµ‹çš„æ¨¡å‹

        å‚æ•°ï¼š
            model_type (str): æ¨¡å‹ç±»å‹ï¼Œå¯é€‰ 'lstm', 'transformer'ï¼Œå†³å®šä½¿ç”¨å“ªç§é¢„æµ‹æ¨¡å‹ã€‚
            sequence_length (int): è¾“å…¥åºåˆ—é•¿åº¦ï¼Œå†³å®šæ¯æ¬¡é¢„æµ‹ä½¿ç”¨å¤šå°‘æ­¥å†å²æ•°æ®ã€‚
            prediction_horizon (int): é¢„æµ‹åºåˆ—é•¿åº¦ï¼Œå†³å®šæ¯æ¬¡é¢„æµ‹å¤šå°‘å¤©çš„æ•°æ®ï¼ŒçŸ­æœŸ90ï¼Œé•¿æœŸ365ã€‚
            epochs (int): è®­ç»ƒçš„æœ€å¤§è½®æ•°ã€‚
            batch_size (int): æ‰¹é‡å¤§å°ã€‚

        åŠŸèƒ½ï¼š
            - å‡†å¤‡è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†
            - åˆå§‹åŒ–å¹¶è®­ç»ƒæŒ‡å®šçš„é¢„æµ‹æ¨¡å‹
            - ä½¿ç”¨ MSELoss è¿›è¡Œå›å½’ä»»åŠ¡ä¼˜åŒ–
            - ä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦å’Œæ—©åœæœºåˆ¶é˜²æ­¢è¿‡æ‹Ÿåˆ
            - åœ¨è®­ç»ƒç»“æŸååŠ è½½éªŒè¯é›†æŸå¤±æœ€ä½çš„æ¨¡å‹
            - å¯è§†åŒ–è®­ç»ƒå’ŒéªŒè¯æŸå¤±å˜åŒ–è¶‹åŠ¿
        """

        print(f"\nğŸ§  Training {model_type.upper()} model...")

        # ===============================
        # 1ï¸âƒ£ æ•°æ®é¢„å¤„ç†ä¸åºåˆ—ç”Ÿæˆ
        # ===============================
        # å¯¹é¢„å¤„ç†åçš„å®Œæ•´æ•°æ®è¿›è¡Œå½’ä¸€åŒ–å¹¶ç”Ÿæˆåºåˆ—ï¼Œä»¥ä¾¿è¾“å…¥æ¨¡å‹è¿›è¡Œæ—¶åºé¢„æµ‹
        scaled_data1, feature_cols1 = self.prepare_sequences(self.train_processed, sequence_length)
        scaled_data2, feature_cols2 = self.prepare_sequences(self.train_processed, sequence_length)

        # åˆ›å»ºç”¨äºæ—¶é—´åºåˆ—çš„ Dataset ç±»ï¼Œè¿”å›å½¢å¦‚ (batch_x, batch_y) çš„è¿­ä»£å™¨
        train_dataset = TimeSeriesDataset(scaled_data1, sequence_length=sequence_length, prediction_horizon=prediction_horizon)
        val_dataset = TimeSeriesDataset(scaled_data2, sequence_length=sequence_length, prediction_horizon=prediction_horizon)

        # ===============================
        # 2ï¸âƒ£ åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
        # ===============================

        # åˆ›å»º PyTorch DataLoaderï¼Œä¾¿äºåˆ†æ‰¹åŠ è½½æ•°æ®
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

        # ===============================
        # 3ï¸âƒ£ åˆå§‹åŒ–æŒ‡å®šç±»å‹çš„æ¨¡å‹
        # ===============================
        input_size = len(feature_cols1) + 1  # è¾“å…¥ç‰¹å¾æ•°é‡ï¼ˆç‰¹å¾åˆ—æ•° + ç›®æ ‡åˆ—ï¼‰

        if model_type == 'lstm':
            model = LSTMForecaster(input_size=input_size,output_size=prediction_horizon).to(self.device)
        elif model_type == 'transformer':
            model = TransformerForecaster(input_size=input_size, output_size=prediction_horizon).to(self.device)
        elif model_type == 'timemixer':
            model = TimeMixer(input_size=input_size, output_size=prediction_horizon).to(self.device)

        else:
            raise ValueError(f"Unknown model type: {model_type}")

        # ===============================
        # 4ï¸âƒ£ å®šä¹‰æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨
        # ===============================
        criterion = nn.MSELoss()  # å‡æ–¹è¯¯å·®ç”¨äºå›å½’æŸå¤±
        optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # Adam ä¼˜åŒ–å™¨
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(  # åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡
            optimizer,
            patience=5,
            factor=0.5
        )

        # ===============================
        # 5ï¸âƒ£ å¼€å§‹è®­ç»ƒå¾ªç¯
        # ===============================
        train_losses = []
        val_losses = []
        best_val_loss = float('inf')  # ç”¨äºè®°å½•æœ€ä½³éªŒè¯æŸå¤±
        patience_counter = 0  # ç”¨äºæ—©åœ

        for epoch in range(epochs):
            # ğŸ”¹è®­ç»ƒé˜¶æ®µ
            model.train()
            train_loss = 0
            for batch_x, batch_y in train_loader:
                batch_x, batch_y = batch_x.to(self.device), batch_y.to(self.device)

                optimizer.zero_grad()  # æ¢¯åº¦æ¸…é›¶
                outputs = model(batch_x)  # å‰å‘ä¼ æ’­
                loss = criterion(outputs, batch_y)  # è®¡ç®—æŸå¤±
                loss.backward()  # åå‘ä¼ æ’­

                # æ¢¯åº¦è£å‰ªï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

                optimizer.step()  # æ›´æ–°å‚æ•°
                train_loss += loss.item()  # ç´¯åŠ è®­ç»ƒæŸå¤±

            # ğŸ”¹éªŒè¯é˜¶æ®µ
            model.eval()
            val_loss = 0
            with torch.no_grad():
                for batch_x, batch_y in val_loader:
                    batch_x, batch_y = batch_x.to(self.device), batch_y.to(self.device)
                    outputs = model(batch_x)
                    val_loss += criterion(outputs, batch_y).item()

            # ğŸ”¹è®°å½•å¹³å‡æŸå¤±
            train_loss /= len(train_loader)
            val_loss /= len(val_loader)
            train_losses.append(train_loss)
            val_losses.append(val_loss)

            scheduler.step(val_loss)  # æ ¹æ®éªŒè¯æŸå¤±è°ƒæ•´å­¦ä¹ ç‡

            # ğŸ”¹æ—©åœæœºåˆ¶ä¸æ¨¡å‹ä¿å­˜
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                patience_counter = 0
                torch.save(model.state_dict(), f'best_{model_type}_model.pth')
            else:
                patience_counter += 1

            # æ¯ 10 è½®æ‰“å°ä¸€æ¬¡è¿›åº¦
            if epoch % 10 == 0:
                print(f'Epoch {epoch}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')

            # å½“éªŒè¯é›†æŸå¤±å¤šæ¬¡ä¸å†æå‡æ—¶ï¼Œæå‰åœæ­¢è®­ç»ƒ
            if patience_counter >= 10:
                print(f"Early stopping at epoch {epoch}")
                break

        # ===============================
        # 6ï¸âƒ£ åŠ è½½éªŒè¯æŸå¤±æœ€ä½çš„æ¨¡å‹å‚æ•°
        # ===============================
        model.load_state_dict(torch.load(f'best_{model_type}_model.pth'))
        self.models[model_type] = model

        # ===============================
        # 7ï¸âƒ£ å¯è§†åŒ–è®­ç»ƒä¸éªŒè¯æŸå¤±å˜åŒ–æ›²çº¿
        # ===============================
        plt.figure(figsize=(10, 6))
        plt.plot(train_losses, label='Training Loss')
        plt.plot(val_losses, label='Validation Loss')
        plt.title(f'{model_type.upper()} Training History')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        plt.grid(True)
        plt.show()

        return model



    def evaluate_models(self, prediction_horizon=90):
        """
        å¯¹æ‰€æœ‰å·²è®­ç»ƒçš„ PyTorch æ¨¡å‹è¿›è¡Œé¢„æµ‹è¯„ä¼°

        åŠŸèƒ½ï¼š
            - ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹
            - å°†é¢„æµ‹å€¼åå½’ä¸€åŒ–å›çœŸå®å•ä½
            - è®¡ç®— MSEã€MAEã€RMSEã€MAPE å››é¡¹è¯„ä»·æŒ‡æ ‡
            - è¾“å‡ºå¯¹æ¯”è¡¨æ ¼åŠå¯è§†åŒ–æŸ±çŠ¶å›¾
        """

        print("\nğŸ“Š Evaluating models...")

        results = {}  # ç”¨äºå­˜å‚¨æ¯ä¸ªæ¨¡å‹çš„è¯„ä¼°ç»“æœ

        # ==============================================
        # 1ï¸âƒ£ éå†éœ€è¦è¯„ä¼°çš„ PyTorch æ¨¡å‹
        # ==============================================
        for model_name in ['lstm', 'transformer', 'timemixer']:
            if model_name in self.models:
                try:
                    # ==============================================
                    # 1.1 å‡†å¤‡æµ‹è¯•é›†çš„æ»‘åŠ¨çª—å£è¾“å…¥
                    # ==============================================
                    scaled_data, feature_cols = self.prepare_sequences(self.test_processed, sequence_length=90)
                    test_dataset = TimeSeriesDataset(scaled_data, sequence_length=90, prediction_horizon=prediction_horizon)
                    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

                    model = self.models[model_name]
                    model.eval()  # åˆ‡æ¢è‡³è¯„ä¼°æ¨¡å¼

                    predictions = []
                    actuals = []

                    # ==============================================
                    # 1.2 æ¨¡å‹é¢„æµ‹å¹¶æ”¶é›†é¢„æµ‹å€¼å’ŒçœŸå®å€¼
                    # ==============================================
                    with torch.no_grad():
                        for batch_x, batch_y in test_loader:
                            batch_x = batch_x.to(self.device)
                            outputs = model(batch_x)
                            predictions.extend(outputs.cpu().numpy().flatten())
                            actuals.extend(batch_y.numpy().flatten())

                    # ==============================================
                    # 1.3 åå½’ä¸€åŒ–é¢„æµ‹å€¼å’ŒçœŸå®å€¼ä»¥ä¾¿è®¡ç®—çœŸå®è¯¯å·®ï¼ˆè¿™æ ·è¯¯å·®å·¨å¤§æ— æ¯”ï¼‰
                    # ==============================================
                    predictions = np.array(predictions).reshape(-1, 1)
                    actuals = np.array(actuals).reshape(-1, 1)

                    predictions = self.scalers['target_scaler'].inverse_transform(predictions).flatten()
                    actuals = self.scalers['target_scaler'].inverse_transform(actuals).flatten()

                    # ==============================================
                    # 1.4 è®¡ç®—è¯„ä¼°æŒ‡æ ‡
                    # ==============================================
                    mse = mean_squared_error(actuals, predictions)
                    mae = mean_absolute_error(actuals, predictions)
                    rmse = np.sqrt(mse)
                    mape = np.mean(np.abs((actuals - predictions) / actuals)) * 100

                    results[model_name] = {
                        'MSE': mse,
                        'MAE': mae,
                        'RMSE': rmse,
                        'MAPE': mape
                    }

                except Exception as e:
                    print(f"Error evaluating {model_name}: {e}")

        # ==============================================
        # 2ï¸âƒ£ è¾“å‡ºç»“æœè¡¨æ ¼ä¸å¯è§†åŒ–
        # ==============================================
        if results:
            results_df = pd.DataFrame(results).T  # è½¬ç½®ä»¥ä¾¿æ¨¡å‹åä¸ºè¡Œï¼ŒæŒ‡æ ‡ä¸ºåˆ—

            print("\nğŸ“Š Model Evaluation Results:")
            print(results_df.round(4))

            # ç»˜åˆ¶å››ä¸ªæŒ‡æ ‡çš„æŸ±çŠ¶å›¾ä¾¿äºå¯¹æ¯”
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            metrics = ['MSE', 'MAE', 'RMSE', 'MAPE']

            for i, metric in enumerate(metrics):
                ax = axes[i // 2, i % 2]
                results_df[metric].plot(kind='bar', ax=ax)
                ax.set_title(f'{metric} by Model')
                ax.set_ylabel(metric)
                ax.tick_params(axis='x', rotation=45)

            plt.tight_layout()
            plt.show()




    def predict_future(self, model_name='lstm', steps=90):
        """
        ä½¿ç”¨å·²è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæœªæ¥ steps æ­¥é¢„æµ‹

        åŠŸèƒ½ï¼š
            - ä½¿ç”¨è®­ç»ƒå¥½çš„ LSTM/Transformer æ¨¡å‹è¿›è¡Œæœªæ¥æ»šåŠ¨é¢„æµ‹
            - å°†é¢„æµ‹ç»“æœåå½’ä¸€åŒ–å›çœŸå®å•ä½ï¼ˆkWï¼‰
            - å¯è§†åŒ–æœ€è¿‘ä¸€å‘¨çš„å†å²å€¼ + æœªæ¥é¢„æµ‹å€¼å¯¹æ¯”æ›²çº¿
            - è¿”å›é¢„æµ‹å€¼å’Œå¯¹åº”çš„æœªæ¥æ—¶é—´ç´¢å¼•ï¼Œä¾¿äºè¿›ä¸€æ­¥åˆ†ææˆ–ä¸çœŸå®å€¼å¯¹æ¯”
        """

        if model_name not in self.models:
            print(f"Model {model_name} not trained yet")
            return None

        print(f"\nğŸ”® Making {steps} step predictions using {model_name}...")

        model = self.models[model_name]
        model.eval()  # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼

        # ==============================================
        # 1ï¸âƒ£ ä»å·²å¤„ç†æ•°æ®ä¸­è·å–æœ€åä¸€ä¸ªåºåˆ—ï¼ˆç”¨äºé¢„æµ‹èµ·ç‚¹ï¼‰
        # ==============================================
        sequence_length = 90
        scaled_data, feature_cols = self.prepare_sequences(self.test_processed, sequence_length=sequence_length)
        first_sequence = scaled_data.iloc[:sequence_length].values   # shape: (sequence_length, feature_dim)

        predictions = []  # ç”¨äºä¿å­˜é¢„æµ‹å€¼ï¼ˆå½’ä¸€åŒ–çŠ¶æ€ï¼‰
        current_sequence = torch.FloatTensor(first_sequence).unsqueeze(0).to(self.device)
        # shape: (1, sequence_length, feature_dim)

        # ==============================================
        # 2ï¸âƒ£ ç›´æ¥é¢„æµ‹ steps å¤©çš„æ•°æ®
        # ==============================================
        with torch.no_grad():
            pred = model(current_sequence)  # æ¨¡å‹ä¸€æ¬¡æ€§é¢„æµ‹æ•´ä¸ªåºåˆ—
            predictions = pred.cpu().numpy().flatten()  # å°†è¾“å‡ºè½¬æ¢ä¸ºå¯ç”¨çš„ NumPy æ•°ç»„

        # ==============================================
        # 3ï¸âƒ£ å°†é¢„æµ‹å€¼åå½’ä¸€åŒ–å›çœŸå®å•ä½ (kW)
        # ==============================================
        predictions = np.array(predictions).reshape(-1, 1)
        predictions = self.scalers['target_scaler'].inverse_transform(predictions).flatten()


        # 4ï¸âƒ£ åˆ›å»ºå¯¹åº”é¢„æµ‹æ—¶é—´ç´¢å¼•
        # ==============================================
        first_date = self.test_processed.index[0]
        future_dates = pd.date_range(start=self.test_processed.index[sequence_length] + pd.Timedelta(days=1),
                                     periods=steps, freq='D')

        # ==============================================
        # 5ï¸âƒ£ å¯è§†åŒ–ç»“æœ
        # ==============================================
        plt.figure(figsize=(15, 8))

        # 1ï¸âƒ£ æå–ä» sequence_length å¼€å§‹çš„æ•°æ®ï¼ˆçœŸå®æ•°æ®ï¼‰
        real_data = self.test_processed['global_active_power'].iloc[sequence_length:sequence_length + steps]

        # 2ï¸âƒ£ åˆ›å»ºåˆå¹¶çš„æ—¥æœŸç´¢å¼•ï¼ˆçœŸå®æ•°æ®å’Œé¢„æµ‹æ•°æ®ï¼‰
        combined_dates = pd.date_range(start=self.test_processed.index[sequence_length], periods=steps, freq='D')

        # 3ï¸âƒ£ åˆå¹¶çœŸå®æ•°æ®å’Œé¢„æµ‹æ•°æ®
        combined_data = np.concatenate([real_data.values, predictions])

        # 4ï¸âƒ£ ç»˜åˆ¶çœŸå®æ•°æ®å’Œé¢„æµ‹æ•°æ®çš„å¯¹æ¯”
        plt.plot(combined_dates, real_data, label='Real Data', color='blue')  # çœŸå®æ•°æ®
        plt.plot(combined_dates, predictions, label='Prediction', color='red', linestyle='--')  # é¢„æµ‹æ•°æ®

        # 5ï¸âƒ£ è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
        plt.title(f'Real vs. Predicted Data using {model_name.upper()}')
        plt.xlabel('Date')
        plt.ylabel('Global Active Power (kW)')
        plt.legend()
        plt.grid(True)
        plt.show()

        # ==============================================
        # 6ï¸âƒ£ è¿”å›é¢„æµ‹ç»“æœå’Œæœªæ¥æ—¶é—´ç´¢å¼•ä¾¿äºåç»­å¯¹æ¯”çœŸå®å€¼
        # ==============================================
        return predictions, future_dates


    def run_complete_analysis(self):
        """
        ğŸ” è¿è¡Œå®Œæ•´çš„ç”µåŠ›è´Ÿè·åˆ†ææµç¨‹

        åŒ…å«æ­¥éª¤ï¼š
            1. è®­ç»ƒæ·±åº¦å­¦ä¹ é¢„æµ‹æ¨¡å‹ï¼ˆLSTMã€GRUã€TCNï¼‰
            2. è®­ç»ƒ Prophet æ—¶é—´åºåˆ—æ¨¡å‹
            3. è®­ç»ƒå¼‚å¸¸æ£€æµ‹æ¨¡å‹ï¼ˆAutoencoderï¼‰
            4. å¤šç§æ–¹æ³•æ£€æµ‹å¼‚å¸¸ï¼ˆIsolation Forestã€ç»Ÿè®¡ã€Autoencoderï¼‰
            5. è¯„ä¼°é¢„æµ‹æ¨¡å‹æ€§èƒ½ï¼ˆMSEã€MAEã€RMSEã€MAPEï¼‰
            6. ä½¿ç”¨ LSTM è¿›è¡Œæœªæ¥ 48 å°æ—¶æ»šåŠ¨é¢„æµ‹å¹¶å¯è§†åŒ–

        ç”¨é€”ï¼š
            - å¿«é€Ÿæ‰§è¡Œå…¨æµç¨‹åˆ†æï¼Œé€‚åˆè°ƒè¯•ã€æµ‹è¯•ä¸æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆ
        """
        print("ğŸš€ Starting Complete Energy Consumption Analysis...")

        # ==============================================
        # 1ï¸âƒ£ è®­ç»ƒæ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹
        # ==============================================
        print("\n" + "=" * 50)
        print("TRAINING FORECASTING MODELS")
        print("=" * 50)

        self.train_pytorch_model('lstm', epochs=30)
        #self.train_pytorch_model('gru', epochs=30)


        # ==============================================
        # 2ï¸âƒ£ è¯„ä¼°é¢„æµ‹æ¨¡å‹æ€§èƒ½
        # ==============================================
        self.evaluate_models()  # è‡ªåŠ¨è¯„ä¼° LSTM çš„é¢„æµ‹æ•ˆæœï¼ˆç»˜å›¾ + æ‰“å°è¡¨ï¼‰


        # ==============================================
        # 3ï¸âƒ£ æœªæ¥ 90 å¤©æ»šåŠ¨é¢„æµ‹å¹¶å¯è§†åŒ–
        # ==============================================
        print("\n" + "=" * 50)
        print("MAKING FUTURE PREDICTIONS")
        print("=" * 50)

        self.predict_future('lstm', steps=90)  # ä½¿ç”¨ LSTM æ¨¡å‹é¢„æµ‹æœªæ¥90 å¤©

        print("\nâœ… Complete analysis finished!")


